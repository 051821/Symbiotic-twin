# ğŸ“˜ SYMBIOTIC-TWIN
## Federated Multi-Agent Cognitive Digital Twin Framework for Secure Edge Intelligence

---

## ğŸš€ Project Overview

SYMBIOTIC-TWIN is a distributed federated learning framework that simulates intelligent IoT edge devices (Digital Twins) collaboratively training a global AI model **without sharing raw data**.

The system combines:

- Federated Learning (FedAvg)
- Multi-Agent Edge Simulation
- Cognitive Optimization
- Adaptive Aggregation
- Structured Logging
- Real-Time Performance Dashboard
- YAML-Based Configuration
- Dockerized Architecture

---

## ğŸ— System Architecture

The system consists of:

- 3 Edge Nodes (Simulated IoT / Docker containers)
- 1 Federated Server
- 1 Streamlit Dashboard
- Shared Model Layer
- Metrics Tracking Layer
- Centralized YAML Configuration
- Structured Logging System

### High-Level Workflow

```
Edge 1  \
Edge 2   --->  Federated Server  --->  Aggregation  --->  Global Model
Edge 3  /
```

**Dashboard monitors:**
- Accuracy
- Latency
- Energy Consumption
- Aggregation Weights
- Node Activity Logs

---

## ğŸ›  Tools & Technologies Used

| Tool | Purpose |
|------|---------|
| Python | Core programming language |
| PyTorch | Model training and inference |
| FastAPI | Federated server API |
| Uvicorn | ASGI server runtime |
| Streamlit | Performance dashboard |
| Docker | Multi-node simulation |
| PyYAML | Configuration management |
| Matplotlib / Plotly | Visualization |
| Logging module | Structured logging |

---

## ğŸ§  Federated Learning Logic

**Each edge:**
1. Loads device-specific data
2. Trains model locally
3. Sends model weights to server
4. Receives updated global model
5. Repeats for N rounds

**The server:**
1. Collects local model updates
2. Computes aggregation weights
3. Applies weighted averaging
4. Updates global model
5. Broadcasts back to edges

---

## ğŸ“Š Federated Aggregation Weights

The federated averaging weight formula:

$$w_i = \frac{n_i}{\sum_{k=1}^{N} n_k}$$

Where:
- $n_i$ = number of samples in edge $i$
- $\sum n_k$ = total samples across all edges
- $w_i$ = contribution weight of edge $i$

The global model update:

$$\theta_{global} = \sum_{i=1}^{N} w_i \cdot \theta_i$$

Where $\theta_i$ = local model weights from edge $i$.

### ğŸ“ˆ Example From This Dataset

| Edge | Training Samples | Weight |
|------|-----------------|--------|
| Edge 1 | 149,960 | 0.46 |
| Edge 2 | 89,452 | 0.28 |
| Edge 3 | 84,734 | 0.26 |

$$w_1 = \frac{149960}{324146} \approx 0.46 \quad w_2 = \frac{89452}{324146} \approx 0.28 \quad w_3 = \frac{84734}{324146} \approx 0.26$$

This demonstrates:
- âœ” Non-IID distribution
- âœ” Weighted aggregation
- âœ” Edge contribution transparency

---

## ğŸ“‚ Project Structure

```
symbiotic-twin/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ logging_config.py
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ aggregator.py
â”‚   â”œâ”€â”€ reputation.py
â”‚   â”œâ”€â”€ model_manager.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ edge/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ cognitive_layer.py
â”‚   â”œâ”€â”€ communication.py
â”‚   â””â”€â”€ data_loader.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ accuracy.py
â”‚   â”œâ”€â”€ latency.py
â”‚   â”œâ”€â”€ energy.py
â”‚   â””â”€â”€ tracker.py
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ serialization.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â””â”€â”€ partition.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ mock_feeder.py
â”‚
â”œâ”€â”€ logs/
â”œâ”€â”€ data/                    # Dataset & partitions (created at runtime)
â”‚
â”œâ”€â”€ docker-compose.yml       # Orchestrates server, edge1â€“3, dashboard
â”œâ”€â”€ Dockerfile.server        # Federated server image (FastAPI/Uvicorn)
â”œâ”€â”€ Dockerfile.edge          # Edge node image (PyTorch, training)
â”œâ”€â”€ Dockerfile.dashboard     # Streamlit dashboard image
â”œâ”€â”€ requirements-server.txt  # Server dependencies
â”œâ”€â”€ requirements-edge.txt   # Edge dependencies (PyTorch CPU, etc.)
â”œâ”€â”€ requirements-dashboard.txt
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ quickstart.sh            # One-command Docker setup
â”œâ”€â”€ verify-docker-setup.sh   # Validate Docker config before run
â”œâ”€â”€ optimize-and-build.sh    # Clean build & optional optimizations
â””â”€â”€ README.md
```

---

## âš™ Configuration System

### `config/config.yaml`

Central configuration file controlling:
- Number of edges
- Number of federated rounds
- Learning rate
- Batch size
- Aggregation settings
- Logging level
- Dataset paths

```yaml
system:
  num_edges: 3
  num_rounds: 10
  learning_rate: 0.001

aggregation:
  adaptive_weighting: true
```

### `config/loader.py`

Loads YAML configuration globally across all modules:

```python
config = load_config()
```

### `config/logging_config.py`

Provides centralized logging configuration:
- File-based logging
- Console logging
- Timestamped format
- Separate log file per node

---

## ğŸ“ Module Responsibilities

### ğŸ”¹ `shared/`

Contains components shared by both edge nodes and the server.

| File | Responsibility |
|------|---------------|
| `model.py` | Defines neural network architecture â€” Input: 7 IoT features, Output: 3 classes (Normal / Warning / Critical) |
| `serialization.py` | Handles model `state_dict` conversion, tensor-to-dict transformation, and safe communication format |
| `utils.py` | Common utility functions |

---

### ğŸŒ `edge/`

Simulates Digital Twin IoT agents. Each edge container runs independently.

#### `edge/main.py`

Edge container entry point.

**Workflow:**
1. Load device partition
2. Train locally
3. Compute metrics
4. Send weights to server
5. Receive global model

#### `edge/trainer.py`

Implements:
- Forward pass
- Loss calculation
- Backpropagation
- Accuracy evaluation

#### `edge/data_loader.py`

Loads device-specific partition from the processed dataset using `get_edge_partition(device_id)`.

#### `edge/communication.py`

Handles HTTP communication with the server:
- `POST` model updates
- `GET` global model

#### `edge/cognitive_layer.py`

Implements intelligent adjustments:
- Learning rate tuning
- Energy-aware adaptation
- Multi-objective optimization

---

### ğŸ§  `server/`

Federated coordination layer.

#### `server/main.py`

Starts the FastAPI server and manages the global model lifecycle.

#### `server/routes.py`

Defines API endpoints:

| Endpoint | Purpose |
|----------|---------|
| `/update` | Receive edge model weights |
| `/global-model` | Send aggregated global model |
| `/weights` | Return aggregation weights |

#### `server/aggregator.py`

Implements:
- Standard **FedAvg** algorithm
- Adaptive weighted aggregation
- Reputation-aware contribution

#### `server/model_manager.py`

Maintains:
- Global model state
- Model versioning
- State synchronization across rounds

#### `server/reputation.py`

Tracks:
- Edge contribution quality
- Trust scoring
- Potential anomaly detection

---

### ğŸ“Š `metrics/`

Responsible for system evaluation.

#### `metrics/accuracy.py`

$$\text{Accuracy} = \frac{\text{Correct}}{\text{Total}} \times 100$$

#### `metrics/latency.py`

$$\text{Latency (ms)} = \text{End Time} - \text{Start Time}$$

#### `metrics/energy.py`

$$\text{Energy} \propto \text{Computation Time} \times \text{Model Complexity}$$

#### `metrics/tracker.py`

Stores per-round metrics used by the Streamlit dashboard:
- Accuracy (global and per-edge)
- Latency
- Energy consumption
- Aggregation weights

---

### ğŸ“ `data/`

Data processing layer.

#### `data/preprocess.py`

Performs:
- Timestamp conversion
- Label creation (Normal / Warning / Critical)
- Feature normalization
- Boolean conversion

#### `data/partition.py`

Partitions dataset by device ID, ensuring:
- âœ” Natural Non-IID distribution
- âœ” Edge-specific data isolation
- âœ” Train/test split
- âœ” PyTorch tensor conversion

---

### ğŸ“ˆ `dashboard/`

#### `dashboard/app.py`

Streamlit-based UI displaying:
- Model Accuracy (%) comparison
- Inference Latency graph
- Energy Consumption graph
- Federated Aggregation Weights & bar chart
- Training round progress
- Node health status

---

## ğŸ“ Logging System

Each node generates its own log file:

```
logs/server.log
logs/edge1.log
logs/edge2.log
logs/edge3.log
```

**Log format:**

```
2026-02-18 14:32:11 | INFO | edge1 | Training started | Round: 3
```

Provides:
- Transparency across all nodes
- Debugging capability
- Demonstration clarity

---

## ğŸ”„ Federated Learning Workflow

```
1. Server initializes global model
        â†“
2. Server broadcasts model to all edges
        â†“
3. Each edge trains locally + computes accuracy + sends weights
        â†“
4. Server aggregates weights â†’ updates global model â†’ logs performance
        â†“
5. Repeat for N rounds
```

---

## ğŸ“¦ Installation

**Recommended: run with Docker** (see below). No local Python install required.

For local development without Docker, install dependencies per component:

```bash
# Server (API)
pip install -r requirements-server.txt

# Edge (training; use Python 3.10, PyTorch CPU)
pip install -r requirements-edge.txt

# Dashboard (Streamlit)
pip install -r requirements-dashboard.txt
```

Ensure directories exist: `mkdir -p logs data`. Preprocess and partition data as needed (see `data/`).

---

## ğŸ³ Run Using Docker

**Prerequisites:** Docker and Docker Compose installed and running (e.g. Docker Desktop).

The stack runs five containers: one **server** (FastAPI), three **edge** nodes (PyTorch CPU training), and one **dashboard** (Streamlit). Images are built from `Dockerfile.server`, `Dockerfile.edge`, and `Dockerfile.dashboard` (Python 3.10).

### Option 1: Quick start (recommended)

```bash
chmod +x quickstart.sh
./quickstart.sh
```

This checks Docker, creates `logs/` and `data/`, builds images, starts all services, and prints access URLs.

### Option 2: Manual steps

```bash
# Optional: verify Docker setup
./verify-docker-setup.sh

# Create directories
mkdir -p logs data

# Build and start
docker-compose up --build
```

Run in background: `docker-compose up -d --build`.

### Access URLs

| Service        | URL                        |
|----------------|----------------------------|
| API server     | http://localhost:8000       |
| API docs       | http://localhost:8000/docs |
| Health check   | http://localhost:8000/health |
| Dashboard      | http://localhost:8501      |

### Useful commands

```bash
docker-compose ps          # Status
docker-compose logs -f     # Follow logs
docker-compose stop        # Stop services
docker-compose down        # Stop and remove containers
```

---

## ğŸ“Š Performance Metrics

The system evaluates:

| Metric | Unit |
|--------|------|
| Model Accuracy | % |
| Inference Latency | ms |
| Energy Consumption | J |
| Convergence Speed | rounds |
| Aggregation Weights | ratio |
| Communication Overhead | bytes |

---

## ğŸ¯ Key Features

| Feature | Status |
|---------|--------|
| Federated Learning (FedAvg) | âœ” |
| Real IoT Telemetry Dataset | âœ” |
| Device-Based Natural Partitioning | âœ” |
| Multi-Agent Edge Simulation | âœ” |
| Adaptive & Weighted Aggregation | âœ” |
| Aggregation Weight Visualization | âœ” |
| YAML-Based Configuration | âœ” |
| Structured Logging | âœ” |
| Real-Time Dashboard | âœ” |
| Dockerized Architecture | âœ” |

---

## ğŸ“ Academic Contribution

This project demonstrates how distributed cognitive digital twins can collaboratively learn at the edge while maintaining privacy, reducing latency, and improving energy efficiency. Specifically, it showcases:

- Realistic **Non-IID federated learning** using real IoT telemetry
- **Device-based data partitioning** preserving natural data heterogeneity
- **Weighted model aggregation** proportional to edge sample counts
- **Transparent contribution analysis** via the dashboard
- **Modular distributed architecture** suitable for production deployment