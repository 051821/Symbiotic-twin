# ğŸ“˜ SYMBIOTIC-TWIN
## Federated Multi-Agent Cognitive Digital Twin Framework for Secure Edge Intelligence

---

## ğŸš€ Project Overview

SYMBIOTIC-TWIN is a distributed AI framework that combines:

- Federated Learning
- Multi-Agent Edge Simulation
- Cognitive Optimization
- Adaptive Aggregation
- Structured Logging
- Performance Monitoring Dashboard

The system simulates edge-based digital twins that collaboratively train a global model without sharing raw data, ensuring privacy, scalability, and efficiency.

---

## ğŸ— System Architecture

The system consists of:

- 1 Federated Server
- 3 Edge Nodes (Docker containers)
- 1 Streamlit Dashboard
- Centralized YAML Configuration
- Structured Logging System

### High-Level Workflow

```
Edge 1   \
Edge 2    --->  Federated Server  --->  Aggregation  ---> Global Model
Edge 3   /
```

Dashboard monitors:
- Accuracy
- Latency
- Energy Consumption
- Node activity logs

---

## ğŸ›  Tools & Technologies Used

| Tool | Purpose |
|------|---------|
| Python | Core programming language |
| PyTorch | Model training and inference |
| FastAPI | Federated server API |
| Uvicorn | ASGI server runtime |
| Streamlit | Performance dashboard |
| Docker | Multi-node simulation |
| PyYAML | Configuration management |
| Matplotlib / Plotly | Visualization |
| Logging module | Structured logging |

---

## ğŸ“‚ Project Structure

```
symbiotic-twin/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ logging_config.py
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ aggregator.py
â”‚   â”œâ”€â”€ reputation.py
â”‚   â”œâ”€â”€ model_manager.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ edge/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ cognitive_layer.py
â”‚   â”œâ”€â”€ communication.py
â”‚   â””â”€â”€ data_loader.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ accuracy.py
â”‚   â”œâ”€â”€ latency.py
â”‚   â”œâ”€â”€ energy.py
â”‚   â””â”€â”€ tracker.py
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ serialization.py
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ logs/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ Configuration System

### `config/config.yaml`

Central configuration file controlling:

- Number of edges
- Number of federated rounds
- Learning rate
- Batch size
- Aggregation settings
- Logging level

**Example:**

```yaml
system:
  num_edges: 3
  num_rounds: 10
  learning_rate: 0.001

aggregation:
  adaptive_weighting: true
```

### `config/loader.py`

Loads YAML configuration globally:

```python
config = load_config()
```

Used across server, edge, and dashboard modules.

### `config/logging_config.py`

Provides centralized logging configuration:

- File-based logging
- Console logging
- Timestamped format
- Separate log file per node

---

## ğŸ§  Server Module

### `server/main.py`

Entry point for FastAPI server.

**Responsibilities:**
- Initialize API
- Start aggregation service
- Manage global model lifecycle

### `server/routes.py`

Defines API endpoints:

- `/update` â†’ Receives model updates from edges
- `/global-model` â†’ Sends aggregated model

### `server/aggregator.py`

Implements:
- FedAvg algorithm
- Adaptive weighted aggregation
- Reputation-aware contribution

### `server/reputation.py`

Maintains node trust score based on:
- Historical performance
- Contribution quality
- Model divergence

### `server/model_manager.py`

Handles:
- Global model storage
- Serialization/deserialization
- Version tracking

---

## ğŸŒ Edge Module

Each edge simulates a **Digital Twin Agent**.

### `edge/main.py`

Edge container entry point.

**Workflow:**
1. Load local data
2. Train local model
3. Send weights to server
4. Receive global model
5. Repeat for multiple rounds

### `edge/trainer.py`

Handles:
- Local training
- Backpropagation
- Accuracy computation

### `edge/model.py`

Defines neural network architecture.

### `edge/cognitive_layer.py`

Implements:
- Learning rate adjustment
- Multi-objective optimization
- Energy-aware tuning

### `edge/communication.py`

Handles HTTP communication with server:
- Send model updates
- Fetch global model

### `edge/data_loader.py`

Loads partitioned local dataset (Non-IID simulation).

---

## ğŸ“Š Metrics Module

### `metrics/accuracy.py`

Computes model accuracy:

$$\text{Accuracy} = \frac{\text{Correct}}{\text{Total}} \times 100$$

### `metrics/latency.py`

Measures inference time using `time.time()`:

$$\text{Latency (ms)} = \text{End Time} - \text{Start Time}$$

### `metrics/energy.py`

Simulates energy usage:

$$\text{Energy} \propto \text{Computation Time} \times \text{Model Complexity}$$

### `metrics/tracker.py`

Stores:
- Global accuracy
- Per-edge accuracy
- Latency per round
- Energy metrics

Used by the Streamlit dashboard.

---

## ğŸ“ˆ Dashboard Module

### `dashboard/app.py`

Streamlit-based UI showing:

- Model Accuracy Comparison
- Inference Latency Graph
- Energy Consumption Graph
- Federated Round Progress
- Node Health Status

---

## ğŸ“ Logging System

Each node generates its own log file:

```
logs/server.log
logs/edge1.log
logs/edge2.log
logs/edge3.log
```

**Log format:**

```
2026-02-18 14:32:11 | INFO | edge1 | Training started | Round: 3
```

Provides:
- Transparency
- Debugging capability
- Demonstration clarity

---

## ğŸ”„ Federated Learning Workflow

1. Server initializes global model
2. Server broadcasts model to edges
3. Each edge:
   - Trains locally
   - Computes accuracy
   - Sends weights
4. Server:
   - Aggregates weights
   - Updates global model
   - Logs performance
5. Repeat for N rounds

---

## ğŸ“¦ Installation

```bash
pip install -r requirements.txt
```

---

## ğŸ³ Run Using Docker

```bash
docker-compose up --build
```

---

## ğŸ“Š Performance Metrics

The system evaluates:

- Model Accuracy (%)
- Inference Latency (ms)
- Energy Consumption (J)
- Convergence Speed
- Communication Overhead

---

## ğŸ¯ Key Features

- âœ” Federated Learning Implementation
- âœ” Multi-Agent Edge Simulation
- âœ” YAML-Based Configuration
- âœ” Adaptive Aggregation
- âœ” Structured Logging
- âœ” Real-Time Dashboard
- âœ” Dockerized Architecture

---

## ğŸ“ Academic Contribution

This project demonstrates how distributed cognitive digital twins can collaboratively learn at the edge while maintaining privacy, reducing latency, and improving energy efficiency.